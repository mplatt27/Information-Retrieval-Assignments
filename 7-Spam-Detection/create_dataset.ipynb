{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "  Part 1: Create dataset using trec07_spam from: http://plg.uwaterloo.ca/~gvcormac/treccorpus07/. \n",
    "  Clean the text from each email and save to use later. \n",
    "  \n",
    "  author: MP\n",
    "  date: 4-22-2021\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import email\n",
    "from bs4 import BeautifulSoup\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\mplat\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Functions to read and clean the corpus. \"\"\"\n",
    "\n",
    "\n",
    "def read_index(file_path):\n",
    "    \"\"\" Read in index file. \"\"\"\n",
    "    \n",
    "    ind = []\n",
    "    with open(file_path, 'r', encoding='ISO-8859-1') as f:\n",
    "        lines = f.readlines()\n",
    "        for line in lines:\n",
    "            ind.append(line)\n",
    "    print(\"Extracted {} documents from the corpus\".format(len(ind)))\n",
    "    return ind\n",
    "\n",
    "\n",
    "def gather_email_content(c):\n",
    "    \"\"\" \n",
    "      Use email API get_payload() to extract the text from the email.\n",
    "      Use BeautifulSoup API get_text() when we have html.\n",
    "    \"\"\"\n",
    "    \n",
    "    # a list to save everything\n",
    "    collected_content = []\n",
    "    \n",
    "    # if the payload just returns a string, only append that\n",
    "    if type(c) == str:\n",
    "        collected_content.append(c)\n",
    "        \n",
    "    # if the payload returns a list, it might have multiparts\n",
    "    # recursivly add each part\n",
    "    elif type(c) == list:\n",
    "        for each in c:\n",
    "            if each.is_multipart():\n",
    "                collected_content += gather_email_content(each.get_payload())\n",
    "            else:\n",
    "                collected_content += gather_email_content(each)\n",
    "    \n",
    "    # append the plain or html after recursive return\n",
    "    elif c.get_content_type().split(' ')[0] == 'text/plain':\n",
    "        if type(c.get_payload()) == str:\n",
    "            collected_content.append(c.get_payload())\n",
    "    elif c.get_content_type().split(' ')[0] == 'text/html':\n",
    "        soup = BeautifulSoup(c.get_payload(), 'html.parser')\n",
    "        txt = soup.get_text()\n",
    "        if type(txt) == str and not txt == None:\n",
    "            collected_content.append(txt)\n",
    "            \n",
    "    return ''.join(collected_content)\n",
    "\n",
    "\n",
    "def extract_document(m):\n",
    "    \"\"\" Extract all of the context that we need from the email file. \"\"\"\n",
    "    \n",
    "    content = m.get_payload()\n",
    "    body = gather_email_content(content)\n",
    "\n",
    "    return m['Subject'], body\n",
    "\n",
    "\n",
    "def clean_document(s):\n",
    "    \"\"\" Clean the text to remove punctuation. \"\"\"\n",
    "    toks = word_tokenize(s)\n",
    "    clean_toks = []\n",
    "    for each in toks:\n",
    "        if each.isalpha():\n",
    "            clean_toks.append(each)\n",
    "    return \" \".join(clean_toks)\n",
    "\n",
    "\n",
    "def create_dataset(file_path):\n",
    "    \"\"\" Creates a dataframe of the index. \"\"\"\n",
    "    \n",
    "    # read in the index content as a list of tuples (label, path)\n",
    "    index = read_index(file_path)\n",
    "    \n",
    "    # initialize dictionary to hold information, later will put in pd dataframe\n",
    "    data = {}\n",
    "    \n",
    "    # loop for each email document in the index\n",
    "    for line in tqdm(index):\n",
    "        \n",
    "        # extract label and corresponding email path \n",
    "        line_list = line.split()\n",
    "        label = line_list[0]\n",
    "        doc_path = 'C:/6200-IR/homework-7-mplatt27//trec07p' + line_list[1][2:]\n",
    "        \n",
    "        # open email file\n",
    "        doc_id_s = doc_path.find('inmail.') + len('inmail.')\n",
    "        doc_id = doc_path[doc_id_s:]\n",
    "        with open(doc_path, 'r', encoding='ISO-8859-1') as f:\n",
    "            \n",
    "            # get raw content of email\n",
    "            raw_doc = f.read()\n",
    "            \n",
    "            # get the subject and email content \n",
    "            msg = email.message_from_string(raw_doc)\n",
    "            subject, doc = extract_document(msg)\n",
    "            \n",
    "            \n",
    "            \n",
    "            # clean the email content\n",
    "            clean_doc = clean_document(doc)\n",
    "            \n",
    "            # add to data dictionary\n",
    "            data[doc_id] = {'doc_path' : doc_path, 'raw_doc': raw_doc, 'subject': subject, \n",
    "                           'clean_doc': clean_doc, 'label': label}\n",
    "            f.close()\n",
    "            \n",
    "    # place into dataframe and return\n",
    "    df = pd.DataFrame.from_dict(data, orient='index')\n",
    "    return df\n",
    "                  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                               | 17/75419 [00:00<15:51, 79.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted 75419 documents from the corpus\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 75419/75419 [12:55<00:00, 97.30it/s]\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Main code \"\"\"\n",
    "PTH = \"C:/6200-IR/homework-7-mplatt27/trec07p/full/corpus_index.txt\"\n",
    "corpus_df = create_dataset(PTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "doc_path     False\n",
       "raw_doc      False\n",
       "subject       True\n",
       "clean_doc    False\n",
       "label        False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_df.isna().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_path</th>\n",
       "      <th>raw_doc</th>\n",
       "      <th>subject</th>\n",
       "      <th>clean_doc</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C:/6200-IR/homework-7-mplatt27//trec07p/data/i...</td>\n",
       "      <td>From RickyAmes@aol.com  Sun Apr  8 13:07:32 20...</td>\n",
       "      <td>Generic Cialis, branded quality@</td>\n",
       "      <td>Do you feel the pressure to perform and not ri...</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C:/6200-IR/homework-7-mplatt27//trec07p/data/i...</td>\n",
       "      <td>From bounce-debian-mirrors=ktwarwic=speedy.uwa...</td>\n",
       "      <td>Typo in /debian/README</td>\n",
       "      <td>Hi i just updated from the gulus and I check o...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C:/6200-IR/homework-7-mplatt27//trec07p/data/i...</td>\n",
       "      <td>From 7stocknews@tractionmarketing.com  Sun Apr...</td>\n",
       "      <td>authentic viagra</td>\n",
       "      <td>Mega authenticV I A G R A DISCOUNT priceC I A ...</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C:/6200-IR/homework-7-mplatt27//trec07p/data/i...</td>\n",
       "      <td>From vqucsmdfgvsg@ruraltek.com  Sun Apr  8 13:...</td>\n",
       "      <td>Nice talking with ya</td>\n",
       "      <td>Hey Billy it was really fun going out the othe...</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>C:/6200-IR/homework-7-mplatt27//trec07p/data/i...</td>\n",
       "      <td>From dcube@totalink.net  Sun Apr  8 13:19:30 2...</td>\n",
       "      <td>or trembling; stomach cramps; trouble in sleep...</td>\n",
       "      <td>system of the home It will have the capabiliti...</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            doc_path  \\\n",
       "1  C:/6200-IR/homework-7-mplatt27//trec07p/data/i...   \n",
       "2  C:/6200-IR/homework-7-mplatt27//trec07p/data/i...   \n",
       "3  C:/6200-IR/homework-7-mplatt27//trec07p/data/i...   \n",
       "4  C:/6200-IR/homework-7-mplatt27//trec07p/data/i...   \n",
       "5  C:/6200-IR/homework-7-mplatt27//trec07p/data/i...   \n",
       "\n",
       "                                             raw_doc  \\\n",
       "1  From RickyAmes@aol.com  Sun Apr  8 13:07:32 20...   \n",
       "2  From bounce-debian-mirrors=ktwarwic=speedy.uwa...   \n",
       "3  From 7stocknews@tractionmarketing.com  Sun Apr...   \n",
       "4  From vqucsmdfgvsg@ruraltek.com  Sun Apr  8 13:...   \n",
       "5  From dcube@totalink.net  Sun Apr  8 13:19:30 2...   \n",
       "\n",
       "                                             subject  \\\n",
       "1                  Generic Cialis, branded quality@    \n",
       "2                             Typo in /debian/README   \n",
       "3                                   authentic viagra   \n",
       "4                               Nice talking with ya   \n",
       "5  or trembling; stomach cramps; trouble in sleep...   \n",
       "\n",
       "                                           clean_doc label  \n",
       "1  Do you feel the pressure to perform and not ri...  spam  \n",
       "2  Hi i just updated from the gulus and I check o...   ham  \n",
       "3  Mega authenticV I A G R A DISCOUNT priceC I A ...  spam  \n",
       "4  Hey Billy it was really fun going out the othe...  spam  \n",
       "5  system of the home It will have the capabiliti...  spam  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_df.to_csv(\"C:/6200-IR/homework-7-mplatt27/corpus_df_clean.csv\", header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
